#!/bin/sh

# Chnage username in location value 
location=/cms/users/$USER/datasets
hdir=hdfs://$location

# Remove previous data first
hadoop fs -rm -r $location

PYTHONPATH=$(pwd)/../CMSSpark/src/python ../CMSSpark/bin/run_spark phedex.py --fout=$hdir --yarn --verbose --date=20170228

hadoop fs -test -e $hdir
exists=$?

# Download results and recreate csv files only if results exist in hdfs
if [[ $exists -eq 0 ]]
then
    # Delete previously downloaded directory and download new one
    basename $hdir | xargs rm -rf
    hadoop fs -get $hdir .

    # extract header
    head -1 datasets/2017/02/28/part-00000 > df.csv

    # concatenate all parts except header
    header=`cat df.csv`
    cat datasets/2017/02/28/part* | grep -v $header >> df.csv
fi
